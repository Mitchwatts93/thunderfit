# a random collection of functions that might be useful, e.g. histograms of intensity ratios etc. not built into thunderfit yet


import matplotlib.pyplot as plt
from os.path import join
import numpy as np
from sklearn.mixture import GaussianMixture

#https://scikit-learn.org/stable/auto_examples/neighbors/plot_kde_1d.html
#https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KernelDensity.html
#https://stackoverflow.com/questions/45304016/how-to-get-kernels-from-kernel-density-estimation-preferrably-sklearn-neighbors
#https://stackoverflow.com/questions/45805316/gaussian-mixture-models-of-an-images-histogram


#AG1/AG2 ratio histogram
def plot_ag1_ag2_ratio(bag, key='center', path='./',):
    """

    :param bag:
    :param key:
    :param path:
    :return:
    """
    foursix_vals = np.array([fit[5] for fit in bag.fit_params[key].values()])
    threesix_vals = np.array([fit[4] for fit in bag.fit_params[key].values()])
    u_vals = threesix_vals/foursix_vals
    f = plt.figure()
    ax = f.add_subplot(111)
    plt.hist(x=u_vals, bins='auto', color='#0504aa', alpha=0.7,rwidth=0.85, density=True)
    plt.grid(axis='y', alpha=0.75)
    plt.xlabel('peak center values')
    plt.ylabel('Frequency Density')
    plt.text(0.3, 0.9, r'$\mu=$'+f'{np.round(np.mean(u_vals), 3)}, '+r'$\sigma=$'+f'{np.round(np.std(u_vals), 3)}',horizontalalignment='center',verticalalignment='center', transform=ax.transAxes)
    plt.savefig(join(path, f"Ag1_over_Ag2_ratio_{key}.svg"), transparent=True, format='svg')

#histogram for key at each peak # commented out is the gaussian mixture model for this
def plot_histogram(bag, key='center', gmm=False, path='./'):
    """

    :param bag:
    :param key:
    :param gmm:
    :param path:
    :return:
    """
    for i in range(len(bag.fit_params[key]['0'])):
        key_ = key
        u_vals = np.array([fit[i] for fit in bag.fit_params[key].values()])
        f = plt.figure()
        ax = f.add_subplot(111)
        plt.hist(x=u_vals, bins='auto', color='#0504aa', alpha=0.7,rwidth=0.85, density=True)
        plt.grid(axis='y', alpha=0.75)
        plt.xlabel(f'{key}')
        plt.ylabel('Frequency Density')
        plt.text(0.3, 0.9, r'$\mu=$'+f'{np.round(np.mean(u_vals), 1)}, '+r'$\sigma=$'+f'{np.round(np.std(u_vals), 1)}',horizontalalignment='center',verticalalignment='center', transform=ax.transAxes)
        if gmm:
            vals,bins = np.histogram(u_vals, bins='auto')
            gmm = GaussianMixture(n_components = 3)
            gmm = gmm.fit(u_vals[:,None])
            plt.plot(bins[:None],np.exp(gmm.score_samples(bins[:,None])))
            plt.text(0.3, 0.8, r'GaussianMixture Components:',horizontalalignment='center',verticalalignment='center', transform=ax.transAxes)
            key_ = key + 'gmm'
        plt.savefig(join(path, f"{key_}s_at_{bag.fit_params['center']['0'][i]}.svg"), transparent=True, format='svg')

# correlations of maps
import itertools
import numpy as np
import matplotlib.pyplot as plt
def corr_all_mats(bag, key='center', path='./'):
    """

    :param bag:
    :param key:
    :param path:
    :return:
    """
    peaks = bag.map_matrices[key].keys()
    for pair in itertools.combinations(peaks, 2):
        map_0 = bag.map_matrices[key][pair[0]]
        map_1 = bag.map_matrices[key][pair[1]]
        ssd = np.square(map_0-map_1) # sum of square differences
        plt.imshow(ssd)
        plt.savefig(join(path, f"{key}s_at_{np.nanmean(bag.map_matrices['center'][pair[0]])}, "
                               f"{np.nanmean(bag.map_matrices['center'][pair[1]])}.svg"), transparent=True, format='svg')

def corr_mats(mat1,mat2):
    """

    :param mat1:
    :param mat2:
    :return:
    """
    return np.square(mat1-mat2)


#pca
import dill
bag = dill.load(open('bag_object.d','rb')) # load the bag
vals = [i.y_data_bg_rm for i in bag.thunder_bag.values()] # get the values
coordinates = bag.coordinates
pca = decomposition.PCA(n_components=4)
val_std = StandardScaler().fit_transform(ys) # this will get the pcas from the spatial variation - i.e. can use it in a
#  map scan plot. taking the transpose will give pcas of the data which can be plotted like an x-y spectrum
pcas = pca.fit_transform(val_std)
# this uses pcas as generated above
values_zero = dict(zip(coordinates.keys(),list(pcas[:,0]))) # repeat changing the 0 to the other elements
#...
X_coords, Y_coords, data = {},{},{} # will save vlaues in these
X_coords[0],Y_coords[0], data[0] = map_scan_tools.generate_map_matrix(coordinates, values_zero) # repeat for all the other elements
#...
figs, axs = map_scan_tools.map_scan_plot_dicts(data, X_coords, Y_coords) # generate plots for all the maps
for peak_label in figs.keys():
    map_scan_tools.save_mapscan(peak_label, {}, figs, './', 0) # save all the figures
